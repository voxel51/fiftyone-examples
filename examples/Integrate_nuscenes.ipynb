{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Autogenerated by `scripts/make_examples.py` -->\n",
    "<table align=\"left\">\n",
    "    <td>\n",
    "        <a target=\"_blank\" href=\"https://colab.research.google.com/github/voxel51/fiftyone-examples/blob/master/examples/Integrate_nuscenes.ipynb\">\n",
    "            <img src=\"https://user-images.githubusercontent.com/25985824/104791629-6e618700-5769-11eb-857f-d176b37d2496.png\" height=\"32\" width=\"32\">\n",
    "            Try in Google Colab\n",
    "        </a>\n",
    "    </td>\n",
    "    <td>\n",
    "        <a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/voxel51/fiftyone-examples/blob/master/examples/Integrate_nuscenes.ipynb\">\n",
    "            <img src=\"https://user-images.githubusercontent.com/25985824/104791634-6efa1d80-5769-11eb-8a4c-71d6cb53ccf0.png\" height=\"32\" width=\"32\">\n",
    "            Share via nbviewer\n",
    "        </a>\n",
    "    </td>\n",
    "    <td>\n",
    "        <a target=\"_blank\" href=\"https://github.com/voxel51/fiftyone-examples/blob/master/examples/Integrate_nuscenes.ipynb\">\n",
    "            <img src=\"https://user-images.githubusercontent.com/25985824/104791633-6efa1d80-5769-11eb-8ee3-4b2123fe4b66.png\" height=\"32\" width=\"32\">\n",
    "            View on GitHub\n",
    "        </a>\n",
    "    </td>\n",
    "    <td>\n",
    "        <a href=\"https://github.com/voxel51/fiftyone-examples/raw/master/examples/Integrate_nuscenes.ipynb\" download>\n",
    "            <img src=\"https://user-images.githubusercontent.com/25985824/104792428-60f9cc00-576c-11eb-95a4-5709d803023a.png\" height=\"32\" width=\"32\">\n",
    "            Download notebook\n",
    "        </a>\n",
    "    </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'nuscenes_final' deleted\n"
     ]
    }
   ],
   "source": [
    "!fiftyone datasets delete nuscenes_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-mini...\n",
      "Loading nuScenes-lidarseg...\n",
      "Loading nuScenes-panoptic...\n",
      "32 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "911 instance,\n",
      "12 sensor,\n",
      "120 calibrated_sensor,\n",
      "31206 ego_pose,\n",
      "8 log,\n",
      "10 scene,\n",
      "404 sample,\n",
      "31206 sample_data,\n",
      "18538 sample_annotation,\n",
      "4 map,\n",
      "404 lidarseg,\n",
      "404 panoptic,\n",
      "Done loading in 0.515 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 0.1 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "from nuscenes.nuscenes import NuScenes\n",
    "import fiftyone as fo\n",
    "\n",
    "nusc = NuScenes(version='v1.0-mini', dataroot='/data/sets/nuscenes', verbose=True)\n",
    "\n",
    "dataset = fo.Dataset(\"nuscenes_final\", overwrite=True)\n",
    "dataset.add_group_field(\"group\", default=\"CAM_FRONT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from nuscenes.utils.data_io import load_bin_file\n",
    "from nuscenes.utils.color_map import get_colormap\n",
    "from nuscenes.lidarseg.lidarseg_utils import paint_points_label\n",
    "from nuscenes.utils.data_classes import LidarPointCloud\n",
    "import open3d as o3d\n",
    "import os\n",
    "\n",
    "def load_lidar(lidar_token):\n",
    "\n",
    "    #Grab and Generate Colormaps\n",
    "    gt_from = \"lidarseg\"\n",
    "    lidarseg_filename = \"/data/sets/nuscenes/\" + nusc.get(gt_from, lidar_token)['filename']\n",
    "    colormap = get_colormap()\n",
    "    name2index = nusc.lidarseg_name2idx_mapping\n",
    "\n",
    "    coloring = paint_points_label(lidarseg_filename,None,name2index, colormap=colormap)\n",
    "    filepath = \"/data/sets/nuscenes/\" + nusc.get(\"sample_data\", lidar_token)['filename']\n",
    "    root, extension = os.path.splitext(filepath)\n",
    "\n",
    "    #Load Point Cloud\n",
    "    cloud = LidarPointCloud.from_file(filepath)\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(cloud.points[:3,:].T)\n",
    "    colors = coloring[:,:3]\n",
    "    colors.max()\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    #Save back Point Cloud\n",
    "    o3d.io.write_point_cloud(root, pcd)\n",
    "\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes.utils.geometry_utils import  BoxVisibility\n",
    "\n",
    "def lidar_sample(group, filepath, sensor, lidar_token):\n",
    "    data_path, boxes, camera_intrinsic = nusc.get_sample_data(lidar_token, box_vis_level=BoxVisibility.NONE,)\n",
    "    sample = fo.Sample(filepath=filepath, group=group.element(sensor))\n",
    "    detections = []\n",
    "    for box in boxes:\n",
    "                    \n",
    "        x, y, z = box.orientation.yaw_pitch_roll\n",
    "        w, l, h = box.wlh.tolist()\n",
    "\n",
    "        detection = fo.Detection(\n",
    "                label=box.name,\n",
    "                location=box.center.tolist(),\n",
    "                rotation=[z, y, x],\n",
    "                dimensions=[l,w,h]\n",
    "                )\n",
    "        detections.append(detection)\n",
    "    sample[\"ground_truth\"] = fo.Detections(detections=detections)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes.utils.geometry_utils import box_in_image, view_points\n",
    "import numpy as np\n",
    "\n",
    "def camera_sample(group, filepath, sensor, token):\n",
    "    sample = fo.Sample(filepath=filepath, group=group.element(sensor))\n",
    "    data_path, boxes, camera_intrinsic = nusc.get_sample_data(token, box_vis_level=BoxVisibility.NONE,)\n",
    "    image = Image.open(data_path)\n",
    "    width, height = image.size\n",
    "    shape = (height,width)\n",
    "    polylines = []\n",
    "    for box in boxes:\n",
    "        if box_in_image(box,camera_intrinsic,shape,vis_level=BoxVisibility.ALL):\n",
    "            c = np.array(nusc.colormap[box.name]) / 255.0\n",
    "            #print(box.name)\n",
    "            corners = view_points(box.corners(), camera_intrinsic, normalize=True)[:2, :]\n",
    "            front = [(corners[0][0]/width,corners[1][0]/height),\n",
    "                    (corners[0][1]/width,corners[1][1]/height),\n",
    "                    (corners[0][2]/width,corners[1][2]/height),\n",
    "                    (corners[0][3]/width,corners[1][3]/height),]\n",
    "            back =  [(corners[0][4]/width,corners[1][4]/height),\n",
    "                    (corners[0][5]/width,corners[1][5]/height),\n",
    "                    (corners[0][6]/width,corners[1][6]/height),\n",
    "                    (corners[0][7]/width,corners[1][7]/height),]\n",
    "            #print(corners.shape)\n",
    "            polylines.append(fo.Polyline.from_cuboid(front + back, label=box.name))\n",
    "    sample[\"cuboids\"] = fo.Polylines(polylines=polylines)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 4728/4728 [13.9s elapsed, 0s remaining, 416.6 samples/s]      \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=True&subscription=2cab39d2-fc60-4848-a2e7-2c51f3ec149b\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9a04983820>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from nuscenes.utils.geometry_utils import view_points, BoxVisibility, box_in_image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "groups = [\"CAM_FRONT\", \"CAM_FRONT_RIGHT\", \"CAM_BACK_RIGHT\", \"CAM_BACK\",\n",
    "           \"CAM_BACK_LEFT\", \"CAM_FRONT_LEFT\",\"LIDAR_TOP\", \"RADAR_FRONT\",\n",
    "           \"RADAR_FRONT_LEFT\", \"RADAR_FRONT_RIGHT\", \"RADAR_BACK_LEFT\", \"RADAR_BACK_RIGHT\"]\n",
    "\n",
    "samples = []\n",
    "for scene in nusc.scene:\n",
    "    my_scene = scene\n",
    "    token = my_scene['first_sample_token']\n",
    "    my_sample = nusc.get('sample', token)\n",
    "    last_sample_token = my_scene['last_sample_token']\n",
    "    \n",
    "    while not my_sample[\"next\"] == \"\":\n",
    "        scene_token = my_sample[\"scene_token\"]\n",
    "        lidar_token = my_sample[\"data\"][\"LIDAR_TOP\"]\n",
    "        group = fo.Group()\n",
    "        for sensor in groups:\n",
    "            data = nusc.get('sample_data', my_sample['data'][sensor])\n",
    "            filepath = \"/data/sets/nuscenes/\" + data[\"filename\"]\n",
    "            if data[\"sensor_modality\"] == \"lidar\":\n",
    "                filepath = load_lidar(lidar_token)\n",
    "                sample = lidar_sample(group,filepath, sensor, lidar_token)\n",
    "\n",
    "                \n",
    "            elif data[\"sensor_modality\"] == \"camera\":\n",
    "                sample = camera_sample(group, filepath, sensor, my_sample['data'][sensor])\n",
    "            else:\n",
    "                sample = fo.Sample(filepath=filepath, group=group.element(sensor))\n",
    "\n",
    "            sample[\"token\"] = data[\"token\"]\n",
    "            sample[\"ego_pose_token\"] = data[\"ego_pose_token\"]\n",
    "            sample[\"calibrated_sensor_token\"] = data[\"calibrated_sensor_token\"]\n",
    "            sample[\"timestamp\"] = data[\"timestamp\"]\n",
    "            sample[\"is_key_frame\"] = data[\"is_key_frame\"]\n",
    "            sample[\"prev\"] = data[\"prev\"]\n",
    "            sample[\"next\"] = data[\"next\"]\n",
    "            sample[\"scene_token\"] = scene_token\n",
    "\n",
    "            \n",
    "            samples.append(sample)\n",
    "\n",
    "        token = my_sample[\"next\"]\n",
    "\n",
    "        my_sample = nusc.get('sample', token)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "dataset.add_samples(samples)\n",
    "view = dataset.group_by(\"scene_token\", order_by=\"timestamp\")\n",
    "session = fo.launch_app(view)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
